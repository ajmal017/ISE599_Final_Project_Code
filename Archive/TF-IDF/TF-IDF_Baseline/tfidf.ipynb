{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning parameter of tf-idf base model \n",
    "# Using first year 10-k & next year stock price(splkit into train & test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import os\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_Outliers(dataframe, column_name, outlierConstant = 1.5):\n",
    "    a = np.array(dataframe[column_name])\n",
    "    upper_quartile = np.percentile(a, 75)\n",
    "    lower_quartile = np.percentile(a, 25)\n",
    "    IQR = (upper_quartile - lower_quartile) * outlierConstant\n",
    "    quartileSet = (lower_quartile - IQR, upper_quartile + IQR)\n",
    "    index_list = []\n",
    "    for i in range(0,len(a)):\n",
    "        value = a[i]\n",
    "        if value <= quartileSet[0] or value >= quartileSet[1]:\n",
    "            index_list.append(i)            \n",
    "    new_dataframe = dataframe[~dataframe.index.isin(index_list)].reset_index(drop = True)    \n",
    "#     print('upper_quartile is',round(upper_quartile,3))\n",
    "#     print('lower_quartile is',round(lower_quartile,3))\n",
    "#     print('IQR is',round(IQR,3))\n",
    "#     print('quartileSet is',quartileSet)\n",
    "#     print('dataset size:', len(a))\n",
    "#     print('Number of outliers:',len(index_list),'\\n')\n",
    "    return new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list = []\n",
    "with open(\"stop_word_new.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        stop_words_list.append(str(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process file, set exclude_digit = True if do not include digit \n",
    "def pre_process(file_content, exclude_digit):\n",
    "    processed_article = file_content.lower()\n",
    "    # Decide whether to exclude the digit or not \n",
    "    if exclude_digit == False:    # Include digit\n",
    "        processed_article = re.sub(',', '', processed_article )\n",
    "        processed_article = re.sub('[^a-zA-Z0-9]', ' ', processed_article )\n",
    "    else:                         # Exclude digit\n",
    "        processed_article = re.sub('[^a-zA-Z]', ' ', processed_article )\n",
    "\n",
    "    processed_article = re.sub(r'\\s+', ' ', processed_article)\n",
    "        \n",
    "    return processed_article.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exclude_Stop_words (processed_article, stop_words_list):\n",
    "    all_words_0 = processed_article    \n",
    "#     print('There are',len(all_words_0),'words.')\n",
    "        \n",
    "    all_words_1 = [word for word in all_words_0 if len(word) >4 ]\n",
    "#     print('There are',len(all_words_1),'has more than 4 characters.')\n",
    "    \n",
    "    all_words_2 = [word for word in all_words_0 if word not in stop_words_list]\n",
    "#     print('There are',len(all_words_2),'after removed stop_words.\\n')\n",
    "\n",
    "    str = ' '\n",
    "    return str.join(all_words_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_encode_tfidf(path, files):\n",
    "    X = []\n",
    "    for filename in files:\n",
    "        if filename != '.DS_Store':\n",
    "            with open(path+'/'+filename,'r') as file:\n",
    "#                 print(filename)\n",
    "                pre_processed_article = file.read()[3000:]\n",
    "                processed_article = pre_process(pre_processed_article, True)\n",
    "                X.append(Exclude_Stop_words(processed_article, stop_words_list))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read match between 10-k file and stok price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('1997_10k_1998_price.csv')\n",
    "path = '/Users/faustune/Desktop/data/1997.full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfy = dfy[dfy['close_adjusted']<70]\n",
    "# dfy.hist('close_adjusted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = remove_Outliers(df,'close_adjusted')\n",
    "files = dfy['filename'].tolist()\n",
    "y = dfy['close_adjusted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-process data: whether( drop stopword; word length<4; include digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = pre_encode_tfidf(path, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform into tfidf matrix\n",
    "# parameter: which 'analyzer' used in vector(char/word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='char',stop_words='english')\n",
    "# vectorizer = TfidfVectorizer(analyzer='word',stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(X0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data, train model, calculate MSE for 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "40.7112268177977\n",
      "1\n",
      "48.52232311688574\n",
      "2\n",
      "42.023805700721994\n",
      "3\n",
      "48.11431703175929\n",
      "4\n",
      "38.93793312518353\n",
      "5\n",
      "44.650736583607696\n",
      "6\n",
      "37.91070003195739\n",
      "7\n",
      "37.666051543695005\n",
      "8\n",
      "32.534756427377715\n",
      "9\n",
      "40.56888365807317\n"
     ]
    }
   ],
   "source": [
    "avg = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(i)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(mse)\n",
    "    avg.append(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate average MSE of 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.16407340370592"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in avg:\n",
    "    sum += i\n",
    "sum/len(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.toarray()\n",
    "# X = pd.DataFrame(X.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
