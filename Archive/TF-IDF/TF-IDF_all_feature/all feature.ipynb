{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined price features with tfidf matrix to build regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import os\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV,LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_Outliers(dataframe, column_name, outlierConstant = 1.5):\n",
    "    a = np.array(dataframe[column_name])\n",
    "    upper_quartile = np.percentile(a, 75)\n",
    "    lower_quartile = np.percentile(a, 25)\n",
    "    IQR = (upper_quartile - lower_quartile) * outlierConstant\n",
    "    quartileSet = (lower_quartile - IQR, upper_quartile + IQR)\n",
    "    index_list = []\n",
    "    for i in range(0,len(a)):\n",
    "        value = a[i]\n",
    "        if value <= quartileSet[0] or value >= quartileSet[1]:\n",
    "            index_list.append(i)            \n",
    "    new_dataframe = dataframe[~dataframe.index.isin(index_list)].reset_index(drop = True)    \n",
    "    return new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list = []\n",
    "with open(\"stop_word_new.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        stop_words_list.append(str(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process file, set exclude_digit = True if do not include digit \n",
    "def pre_process(file_content, exclude_digit):\n",
    "    processed_article = file_content.lower()\n",
    "    # Decide whether to exclude the digit or not \n",
    "    if exclude_digit == False:    # Include digit\n",
    "        processed_article = re.sub(',', '', processed_article )\n",
    "        processed_article = re.sub('[^a-zA-Z0-9]', ' ', processed_article )\n",
    "    else:                         # Exclude digit\n",
    "        processed_article = re.sub('[^a-zA-Z]', ' ', processed_article )\n",
    "\n",
    "    processed_article = re.sub(r'\\s+', ' ', processed_article)\n",
    "        \n",
    "    return processed_article.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exclude_Stop_words (processed_article, stop_words_list):\n",
    "    all_words_0 = processed_article       \n",
    "#     all_words_1 = [word for word in all_words_0 if len(word) >4 ]\n",
    "    all_words_2 = [word for word in all_words_0 if word not in stop_words_list]\n",
    "    str = ' '\n",
    "    return str.join(all_words_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_encode_tfidf(path, files):\n",
    "    X = []\n",
    "    for filename in files:\n",
    "        if filename != '.DS_Store':\n",
    "            with open(path+'/'+filename,'r') as file:\n",
    "#                 print(filename)\n",
    "                pre_processed_article = file.read()[3000:]\n",
    "                processed_article = pre_process(pre_processed_article, False)\n",
    "                X.append(Exclude_Stop_words(processed_article, stop_words_list))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X,y, model_name):\n",
    "    \n",
    "    if model_name == 'linear':\n",
    "        model = LinearRegression().fit(X, y)\n",
    "    if model_name == 'ridge':\n",
    "        model = Ridge(alpha=0.0001).fit(X, y)\n",
    "    if model_name == 'lasso':\n",
    "        model = Lasso(alpha=0.1, max_iter = 100000).fit(X, y)\n",
    "    if model_name == 'RandomForest':\n",
    "        model = RandomForestRegressor(n_estimators = 500, random_state = 1).fit(X, y)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_model(model, x_train, y_train):\n",
    "    cv_mse = cross_val_score(model,x_train, y_train, cv=10, scoring='neg_mean_squared_error' )\n",
    "    cv_mbe = cross_val_score(model,x_train, y_train, cv=10, scoring='neg_mean_absolute_error' )\n",
    "    cv_r2 = cross_val_score(model,x_train, y_train, cv=10, scoring='r2' )\n",
    "    print('CV mse is',round(np.mean(cv_mse),4))\n",
    "    print('CV mbe is',round(np.mean(cv_mbe),4))\n",
    "    print('CV R^2 is',round(np.mean(cv_r2),4))\n",
    "    return(round(np.mean(cv_mse),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding_all(file,path):\n",
    "    d1 = pd.read_csv(file)\n",
    "    d2 = remove_Outliers(d1,'close_adjusted_x')\n",
    "    d3 = remove_Outliers(d2,'close_adjusted_y')\n",
    "    files = d3['filename'].tolist()\n",
    "    y = d3['close_adjusted_y']\n",
    "    X0 = pre_encode_tfidf(path, files)\n",
    "    vectorizer = TfidfVectorizer(analyzer='word',stop_words='english')\n",
    "    X = vectorizer.fit_transform(X0)\n",
    "    X.toarray()\n",
    "    X = pd.DataFrame(X.toarray())\n",
    "    X['high'] = d3['high']\n",
    "    X['low'] = d3['low']\n",
    "    X['close_adjusted_x'] = d3['close_adjusted_x']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best parameters for ridge, lasso and randomforest\n",
    "def choose_parameter(x_train, y_train):\n",
    "    alphas = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    ridgecv = RidgeCV(alphas = alphas, scoring = 'neg_mean_squared_error', normalize = True)\n",
    "    ridgecv.fit(x_train, y_train)\n",
    "    print(ridgecv.alpha_)\n",
    "    lassocv = LassoCV(alphas = alphas, cv = 10, normalize = True, max_iter = 100000)\n",
    "    lassocv.fit(x_train, y_train)\n",
    "    print(lassocv.alpha_)\n",
    "    num_tree = [50, 100, 200, 500]\n",
    "    for tree in num_tree:\n",
    "        print(tree)\n",
    "        model = RandomForestRegressor(n_estimators = tree, random_state = 1)\n",
    "        print('1')\n",
    "        model.fit(x_train, y_train)\n",
    "        print('2')\n",
    "        evaluation = evaluation_model(model, x_train, y_train)\n",
    "    print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using 2002 find best parameters for ridge, lasso and randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path = '/Users/faustune/Desktop/data/2002.full'\n",
    "# file = '2002_10k_2003_price_all_features.csv'\n",
    "# X,y = word_embedding_all(file, path)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "# choose_parameter(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ['1998_10k_1999_price_all_features.csv','1999_10k_2000_price_all_features.csv','2000_10k_2001_price_all_features.csv',\n",
    "    '2001_10k_2002_price_all_features.csv','2002_10k_2003_price_all_features.csv','2003_10k_2004_price_all_features.csv',\n",
    "    '2004_10k_2005_price_all_features.csv','2005_10k_2006_price_all_features.csv','2006_10k_2007_price_all_features.csv']\n",
    "p = '/Users/faustune/Desktop/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model & calculate MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = dict()\n",
    "for file in f:\n",
    "    year = file[0:4]\n",
    "    path = p + year + '.full'\n",
    "    X,y = word_embedding_all(file,path)\n",
    "#     print('embed')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "#     print('split')\n",
    "    reg = model(X_train,y_train, model_name = 'linear')\n",
    "    y_pred1 = reg.predict(X_test)\n",
    "    mse[year].append(mean_squared_error(y_test, y_pred1))\n",
    "#     print(year,'reg')\n",
    "\n",
    "    ridge = model(X_train,y_train, model_name = 'ridge')\n",
    "    y_pred2 = ridge.predict(X_test)\n",
    "    mse[year].append(mean_squared_error(y_test, y_pred2))\n",
    "#     print(year,'ridge')\n",
    "\n",
    "    lasso = model(X_train,y_train, model_name = 'lasso')\n",
    "    y_pred3 = lasso.predict(X_test)\n",
    "    mse[year].append(mean_squared_error(y_test, y_pred3))\n",
    "#     print(year,'lasso')\n",
    "\n",
    "    rf = model(X_train,y_train, model_name = 'RandomForest')\n",
    "    y_pred4 = rf.predict(X_test)\n",
    "    mse[year].append(mean_squared_error(y_test, y_pred4))\n",
    "#     print(year,'rf')\n",
    "#     print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mse_reg, mse_ridge, mse_lasso, mse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(mse, orient='index', columns=['linear', 'ridge', 'lasso', 'forest'])\n",
    "df.to_csv(\"tfidf_all_feature_mse.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
